{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maGbN1lNRbSj",
    "outputId": "748900f7-ed14-4552-aeeb-9921a9a48cf8"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pytest\n",
    "import jax.numpy as jnp\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "WNYRx-kSGCHy",
    "outputId": "83cae9f0-77b5-4601-9803-ad3b3988cfdb"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "current_notebook_folder = Path().resolve()\n",
    "target_file_path = current_notebook_folder.parent / 'spring_run_test.py'\n",
    "absolute_target_path = target_file_path.resolve()\n",
    "sys.path.append(str(current_notebook_folder.parent))\n",
    "from spring_run_test import run_molecule,plot_losses\n",
    "#The running function is in spring_run_test.py\n",
    "from ml_collections import config_dict\n",
    "import vmcnet.train as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = train.default_config.get_default_config()\n",
    "#config = config_dict.ConfigDict()\n",
    "config.save_to_current_datetime_subfolder=False \n",
    "#config.subfolder_name=C_preliminary \n",
    "config.problem.ion_pos=((0.0, 0.0, -2.0), (0.0, 0.0, 2.0))\n",
    "config.problem.ion_charges=(7.0, 7.0) \n",
    "config.problem.nelec=(7, 7)\n",
    "# N2 with bond distance 4.0 Bohr\n",
    "config.vmc.optimizer_type='fisher_acc' # use the ANGD-Fisher-Rao method\n",
    "config.vmc.nchains=2000   \n",
    "config.vmc.optimizer.fisher_acc.nchains_train=config.vmc.nchains  #train\n",
    "config.vmc.nepochs=30000\n",
    "config.vmc.nburns=10000\n",
    "config.eval.nepochs=0 \n",
    "config.model.ferminet.ndeterminants=16 \n",
    "config.model.ferminet.full_det=True \n",
    "config.vmc.checkpoint_every=1000\n",
    "config.vmc.nsteps_per_param_update=10    \n",
    "#config.distribute=True\n",
    "import math\n",
    "\n",
    "lr=math.sqrt(0.001)\n",
    "# lr1, lr2 are step sizes (learning rates) for the parameter and the cotagent variable Phi, respectively. \n",
    "# We set the same values for all experiments.\n",
    "lr1=lr\n",
    "lr2=lr\n",
    "lrd=5e-5  #linear learning rate decay\n",
    "config.vmc.optimizer.fisher_acc.learning_rate1=lr1\n",
    "config.vmc.optimizer.fisher_acc.schedule_type1 = \"inverse_time\"\n",
    "config.vmc.optimizer.fisher_acc.learning_decay_rate1=lrd\n",
    "\n",
    "\n",
    "config.vmc.optimizer.fisher_acc.learning_rate2=lr2\n",
    "config.vmc.optimizer.fisher_acc.schedule_type2 = \"inverse_time\"  \n",
    "config.vmc.optimizer.fisher_acc.learning_decay_rate2=lrd\n",
    "config.vmc.optimizer.fisher_acc.learning_rate2_upper=0.5\n",
    "\n",
    "\n",
    "config.vmc.optimizer.fisher_acc.alpha=0.5/lr2   # initial alpha\n",
    "config.vmc.optimizer.fisher_acc.balance=lr1/lr2 # a hyper-parameter only for tests\n",
    "config.vmc.optimizer.fisher_acc.alpha_schedule_type=\"inverse_time\"  \n",
    "config.vmc.optimizer.fisher_acc.alpha_decay_rate=1e-4  #linear alpha decay\n",
    "config.vmc.optimizer.fisher_acc.alpha_lower_bound=0.1/lr2 #min alpha value\n",
    "\n",
    "\n",
    "config.vmc.optimizer.fisher_acc.beta=0.05 # initial beta\n",
    "config.vmc.optimizer.fisher_acc.beta_schedule_type=\"inverse_time\" \n",
    "config.vmc.optimizer.fisher_acc.beta_decay_rate=5e-5 #linear beta decay\n",
    "\n",
    "config.vmc.optimizer.fisher_acc.mu=0.99  #decay for projected momentum used in spring\n",
    "\n",
    "config.vmc.optimizer.fisher_acc.constrain_norm=True\n",
    "config.vmc.optimizer.fisher_acc.norm_constraint=5.0 # restart threshold for Phi\n",
    "config.vmc.optimizer.fisher_acc.prev_eta_proj='Null_O' #using projected momentum (spring)\n",
    "config.vmc.optimizer.fisher_acc.restart=False\n",
    "config.vmc.optimizer.fisher_acc.nchains=config.vmc.nchains\n",
    "config.vmc.optimizer.fisher_acc.damping=0.005* config.vmc.optimizer.fisher_acc.nchains #multiplying the batch size for scaling \n",
    "\n",
    "config.vmc.print_epoch=1000 #print the iteration number every 1000 iterations\n",
    "config.params_init=None\n",
    "\n",
    "config.model = train.default_config.choose_model_type_in_model_config(config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmap False\n",
      "epoch: 0\n"
     ]
    }
   ],
   "source": [
    "# A running example.\n",
    "# \"Warning: Gradient norm exceeds the constraint\" means the restart step.\n",
    "# loss_list, var_list contain the loss and variance values v.s. iterations respectively.\n",
    "params, optimizer_state, data, key, nans_detected,loss_list,var_list,metric_list=run_molecule(config)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
